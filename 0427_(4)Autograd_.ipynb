{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiRKo3gy6wsk",
        "outputId": "878ee551-360d-496e-d927-745931a789e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w: tensor([[ 0.1925,  0.6529,  0.6729],\n",
            "        [ 0.5192, -0.2886, -0.9218],\n",
            "        [-0.2636, -0.6118, -1.8108],\n",
            "        [-0.3640,  0.4886,  0.3953],\n",
            "        [-0.9337,  0.2703, -0.2080]], requires_grad=True)\n",
            "b: tensor([ 2.4492, -2.8301, -2.1191], requires_grad=True)\n",
            "z : tensor([ 1.5997, -2.3187, -3.9916], grad_fn=<AddBackward0>)\n",
            "loss : 0.6319368481636047\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(5) #input tensor\n",
        "y = torch.zeros(3) #expected output\n",
        "\n",
        "w = torch.randn(5,3, requires_grad=True)\n",
        "print(f\"w: {w}\")\n",
        "\n",
        "b = torch.randn(3, requires_grad = True)\n",
        "print(f\"b: {b}\")\n",
        "\n",
        "z = torch.matmul(x, w) + b\n",
        "print(f\"z : {z}\")\n",
        "\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)\n",
        "print(f\"loss : {loss}\")"
      ]
    }
  ]
}